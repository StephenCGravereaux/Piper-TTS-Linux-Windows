# ğŸ™ï¸ Minimal Ollama + Piper TTS Chatbot

A simple, standalone voice-interactive chatbot using **Ollama** for local LLM inference and **Piper TTS** for offline text-to-speech.

## ğŸ“¦ What's Included

```
piper_ollama_minimal/
â”œâ”€â”€ chatbot.py              # Main chatbot script
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md              # This file
â””â”€â”€ voices/                # Piper voice models
    â”œâ”€â”€ en_US-lessac-medium.onnx
    â”œâ”€â”€ en_US-lessac-medium.onnx.json
    â”œâ”€â”€ en_US-lessac-high.onnx
    â””â”€â”€ en_US-lessac-high.onnx.json
```

## ğŸš€ Quick Start

### Option A: Docker (Recommended) Note: Docker contrainers are isolated from your host's audio system. On Windows/Mac containers can't access your sound card directly. Use option B if you need to hear the voice responses.

```bash
# Pull the image
docker pull stephencgravereaux/piper-ollama-chatbot:latest

# Run interactively (Ollama must be running on host)
docker run -it --rm stephencgravereaux/piper-ollama-chatbot:latest
```

Or build locally:
```bash
docker build -t piper-ollama-chatbot .
docker run -it --rm piper-ollama-chatbot
```

> âš ï¸ **Note:** Ollama must be running on your host machine. The container connects to it via `host.docker.internal:11434`.

---

### Option B: Local Python

#### 1. Install Ollama

**Windows:**
```bash
winget install Ollama.Ollama
```

**Linux/Mac:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

#### 2. Start Ollama Service

```bash
ollama serve
```

Leave this running in a separate terminal.

#### 3. Install Python Dependencies

```bash
pip install -r requirements.txt
```

#### 4. Run the Chatbot

```bash
python chatbot.py
```

## ğŸ¯ Usage

### Basic Usage

```bash
python chatbot.py
```

### Use High Quality Voice

```bash
python chatbot.py --voice high
```

### Use Different Model

```bash
python chatbot.py --model llama3.2:3b
```

### Interactive Commands

Once running, you can:
- **Chat**: Just type your message and press Enter
- **Switch voice**: Type `voice:medium` or `voice:high`
- **Exit**: Type `quit`, `exit`, or `bye`

## ğŸ“‹ Requirements

- **Python 3.8+**
- **Ollama** (running locally)
- **piper-tts** (installed via pip)
- **requests** (installed via pip)

## ğŸ”Š Voice Models

Two voice models are included:

- **en_US-lessac-medium.onnx** - Medium quality (default)
- **en_US-lessac-high.onnx** - High quality (better sound, slower)

Switch between them during chat with `voice:medium` or `voice:high`.

## ğŸ¦™ Supported Models

Any Ollama model works! Popular choices:

- `llama3.2:1b` - Fastest, lowest memory (default)
- `llama3.2:3b` - Balanced performance
- `llama3.2` - Full model, best quality

The chatbot will automatically download the model if not already installed.

## ğŸ› ï¸ Troubleshooting

### "Ollama not running!"

Make sure Ollama is running:
```bash
ollama serve
```

### "Piper not found!"

Install Piper TTS:
```bash
pip install piper-tts
```

### Audio not playing (Linux)

Install an audio player:
```bash
sudo apt install alsa-utils  # For aplay
# or
sudo apt install pulseaudio-utils  # For paplay
```

## ğŸ“ Example Session

```
ğŸ¤– Initializing Chatbot...
ğŸ¦™ Model: llama3.2:1b
ğŸ”Š Voice: en_US-lessac-medium.onnx
âœ… Ollama is running
âœ… Model 'llama3.2:1b' ready
âœ… Piper TTS installed
âœ… Ready!

============================================================
ğŸ™ï¸  OLLAMA + PIPER CHATBOT
============================================================
Commands:
  - Type your message and press Enter
  - Type 'voice:medium' or 'voice:high' to switch voices
  - Type 'quit' or 'exit' to end
============================================================

You: What is the capital of France?

ğŸ‘¤ You: What is the capital of France?
ğŸ¤– Assistant: The capital of France is Paris.
[Audio plays]

You: voice:high
ğŸ”Š Switched to high quality voice

You: Tell me a fun fact
ğŸ‘¤ You: Tell me a fun fact
ğŸ¤– Assistant: Did you know that honey never spoils? Archaeologists have found 3000-year-old honey in Egyptian tombs that was still edible!
[Audio plays]

You: quit
ğŸ‘‹ Goodbye!
```

## ğŸ“ Features

- âœ… **100% Offline** - No internet required after setup
- âœ… **Privacy-First** - All processing happens locally
- âœ… **Voice Output** - Natural-sounding speech synthesis
- âœ… **Two Voice Options** - Medium and high quality
- âœ… **Conversation Memory** - Maintains chat history
- âœ… **Cross-Platform** - Works on Windows, Linux, and macOS
- âœ… **Minimal Dependencies** - Only 2 Python packages

## ğŸ“„ License

This is a minimal demonstration project. Voice models are from the Piper TTS project.

---




